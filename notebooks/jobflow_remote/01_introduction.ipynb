{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbabd9be-a5d9-42f5-8dca-dd7dd9975f00",
   "metadata": {},
   "source": [
    "# Jobflow-remote introduction\n",
    "\n",
    "Jobflow-remote is a free, open-source library serving as a manager for the execution of [jobflow](https://materialsproject.github.io/jobflow/) workflows. Most of the information about how to set up and use jobflow-remote can be found in the [official documentation](https://matgenix.github.io/jobflow-remote/index.html).\n",
    "\n",
    "## Setting up jobflow-remote\n",
    "\n",
    "While the first set to use jobflow-remote would be to [set up the configuration file for one project](https://matgenix.github.io/jobflow-remote/user/install.html), in this tutorial all the configurations have already been performed. Nonetheless it may be helpfull to explore the content of the configuration yaml file that has been generated. The default location is in the `~/.jfremote` folder.\n",
    "A few important sections that you might want to check are:\n",
    "* `name`: the name of the project (note that while it is advisable that the configuration file has the same name as the project, this is not a constraint)\n",
    "* `workers`: the workers available for this project. In this case there are several workers available:\n",
    "  * `cecam`: submits jobs to the Helvetios cluster in the SLURM queue\n",
    "  * `cecam_fw`: runs jobs on the front end of the Helvetios cluster\n",
    "  * `local_slurm`: submits jobs to the `slurm` container in its SLURM queue\n",
    "  * `local`: runs jobs directly in the `jupyter` container.\n",
    "* `queue`: the connection details to the MongoDB database containing the details about the Jobs execution\n",
    "* `jobstore`: the connection details to jobflow's `JobStore`, containing the Job's outputs\n",
    "* `exec_config`: common configurations required to execute Jobs on the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1930a0-45b4-45e6-98d1-04d40b46ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /home/jovyan/.jfremote/PROJECTNAME.yaml # Replace PROJECTNAME with your chosen project name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634573b7-8b7a-4c96-b1ca-f4ed25084113",
   "metadata": {},
   "source": [
    "## The `jf` CLI\n",
    "\n",
    "Most of the interactions with jobflow-remote can be performed using the `jf` command line interface. It is usually executed from the shell, but can also be executed inside this notebook, prepending the command with an exlamation mark `!`.\n",
    "\n",
    "A first step would be to verify that the connections have been properly set up using the `jf project check` command. This will attempt to connect to the workers and the databases and perform few actions. Passing the checks does not guarantee that everything will work fine, but if the checks do not pass connection details need to be revised. \n",
    "The output should look like:\n",
    "```\n",
    "✓ Worker cecam\n",
    "✓ Worker cecam_fe\n",
    "✓ Worker local_slurm\n",
    "✓ Worker local_shell\n",
    "✓ Jobstore\n",
    "✓ Queue store\n",
    "```\n",
    "(Note that if you do not have access to the helvetion cluster you will get an error for the `cecam` and `cecam_fe`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d676c-40b1-4453-ac58-1dcba0f57f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jf project check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2baeb-a45d-4675-8ca0-2c87b16c21e7",
   "metadata": {},
   "source": [
    "Once the connections are properly set, the queue database needs to be prepared with the `jf admin reset` command. This will add a few required documents to the DB and **remove all the Jobs and Flows** present in the database (here we us the `-f` option to avoid being asked for a confirmation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9faa58-5970-4eb8-97e9-6f354d673f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jf admin reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a80e5-71af-4ab0-aa5d-1449e5f9334b",
   "metadata": {},
   "source": [
    "It is now possible to check that no jobs or flow are present in the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e050ad-87c2-428a-80f7-a15827ef3979",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jf job list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4362b3f2-2949-49bd-b7ea-8e22adf8be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jf flow list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7072b-c594-4971-97eb-599adf5704c7",
   "metadata": {},
   "source": [
    "## The first Flow\n",
    "\n",
    "To start using jobflow-remote a Flow needs to be created and added to the DB. Several example Jobs can be found in the `jobflow-remote.testing` module (see the [source code](https://github.com/Matgenix/jobflow-remote/blob/develop/src/jobflow_remote/testing/__init__.py)) and can be used to compose a simple Flow.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Warning:</b> To be executed by jobflow-remote the Job source code should be <b>available in the worker as well</b>. Thus, a simple Job with its source in the notebook will not be present in the worker and jobflow-remote is not able of running it.</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a042e-8b68-475b-aaf0-7407e20636ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobflow import Flow\n",
    "from jobflow_remote.testing import add\n",
    "\n",
    "j1 = add(1, 2)\n",
    "j2 = add(j1.output, 4)\n",
    "\n",
    "flow1 = Flow([j1, j2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b710a0-61a6-464a-8ceb-de6caa2080f6",
   "metadata": {},
   "source": [
    "At this point the Flow has been create but it has not been inserted in the jobflow-remote database. To do so it is necessary to use the `submit_flow` function and choose a worker that will execute the Jobs. For this first example we will use the local worker `local_shell`. The function returns a list of the jobs unique ids that are used to identify them in the database (note that these are strings, even if usually representing integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2741c22a-22b1-4cb7-b91a-6d547835cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobflow_remote import submit_flow\n",
    "\n",
    "job_ids = submit_flow(flow1, worker=\"local_shell\")\n",
    "job_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa06c7f-699d-437f-a5ed-23d6e90313cb",
   "metadata": {},
   "source": [
    "It is now possible to check the presence of the Jobs and Flow in the database using again the `jf` command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d6ad08-6c3f-4da6-8333-d299c2ea1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jf job list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b245258-df89-4894-ab19-e6329277dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jf flow list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2265ec8b-8aa1-4d52-8be9-458dcb787b62",
   "metadata": {},
   "source": [
    "## The Runner\n",
    "\n",
    "Once the Jobs are in the database, they will be executed by jobflow-remote. However, to do so, the Runner has to be activated. \n",
    "In jobflow-remote the Runner refers to one or more processes that handle the whole execution of the jobflow workflows, including the interaction with the worker and the writing of the outputs in the `JobStore`.\n",
    "\n",
    "![Runner schema](https://matgenix.github.io/jobflow-remote/_images/daemon_schema.svg)\n",
    "\n",
    "The Runner performs different tasks, mainly divided in\n",
    "1. checking out jobs from database to start a Flow execution\n",
    "2. updating the states of the Jobs in the queue database\n",
    "3. interacting with the worker hosts to upload/download files and check the job status\n",
    "4. inserting the output data in the output JobStore\n",
    "\n",
    "The runner can be activate with the `jf runner start` command. Its status can be checked with `jf runner status` and `jf runner info` and it can be stopped with `jf runner stop` or `jf runner shutdown`. The Runner **remains active until explicitly stopped**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d67955-9c39-42cf-b8d8-5abc9b7258e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jf runner start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f595284-a756-441d-a812-fc9c04dcd56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jf runner status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955f3a4-1c57-458c-ac6a-b961c8796286",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jf runner info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7289cb95-157c-4419-80af-ecc5ef93a3e7",
   "metadata": {},
   "source": [
    "If everything is running properly you can check the status of the Jobs in the queue. They should reach the `COMPLETED` state in few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faae2a1-356b-48e7-acea-edc4dd9966ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jf job list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7e771-e71d-4106-b295-b6f61de27e2e",
   "metadata": {},
   "source": [
    "## Extracting results\n",
    "\n",
    "Once the Jobs are completed it is possible to extract their outputs. Jobflow-remote does not change this specific aspect of jobflow, so the results can still be extracted from the database using the `JobStore` object or direct database queries. The only difference would be to use jobflow-remote to get the properly configured instance of `JobStore` through the helper function `get_jobstore`. Remeber to **connect** the JobStore before using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334c91d7-4476-4225-8533-6830ca66c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobflow_remote import get_jobstore\n",
    "\n",
    "jobstore = get_jobstore()\n",
    "jobstore.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3439182f-642d-47bf-b4ec-e5b3e5154ee3",
   "metadata": {},
   "source": [
    "Queries will be the same as for standard jobflow and results can be obtained with generic queries, or referring to the job `uuid`. In this case it may also be convenient to use jobflow-remote's `db_id`, which is stored in the outputs `metadata`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04dd347-71f0-41b7-b457-c2234a44abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Output from uuid: \", jobstore.get_output(uuid=j2.uuid))\n",
    "print(\"Output document from uuid: \", jobstore.query_one({\"metadata.db_id\": \"2\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f558065e-1d11-448d-886c-75539aba4e10",
   "metadata": {},
   "source": [
    "## Submitting to a queue based worker \n",
    "\n",
    "Since the previous Flow was executed on the local worker, that is based on the shell execution, no further information needed to be provided. However, to perform real simulations Jobs need to be submitted to queueing systems in the HPC centers (e.g. Slurm, PBS, ...). To do so it is necessary to specify which resources will be used. Let's create a new Flow and submit it to the `local_slurm` worker (or to the `cecam` one). Since the scheduler in this worker is Slurm, some of the standard Slurm input options can be used\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "The handling of the submission to the scheduler is delegated to <a href=\"https://matgenix.github.io/qtoolkit/\">qtoolkit</a>. The available keywords can be checked in the <a href=\"https://github.com/Matgenix/qtoolkit/blob/bcb445b903f3cb78295aa7641944e0bade9a3fb8/src/qtoolkit/io/slurm.py#L150\">Slurm template</a> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0124ceb-7754-4700-a9f5-247daa09f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "j3 = add(1, 2)\n",
    "j4 = add(j3.output, 4)\n",
    "\n",
    "flow2 = Flow([j3, j4])\n",
    "\n",
    "submit_flow(flow2, worker=\"local_slurm\", resources={\"nodes\": 1 , \"ntasks\": 1, \"time\": \"00:10:00\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361786be-cd70-4861-a2a9-5d1484c3ec07",
   "metadata": {},
   "source": [
    "The execution mayb be slightly slower then in the previous case, since now files need to be transferred to the other machine and the Job is running through a queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd943e6-0051-45cc-9d3f-e3fd34d5886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jf job list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
